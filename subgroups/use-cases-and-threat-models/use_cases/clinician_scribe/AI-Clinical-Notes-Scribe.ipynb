{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc7e408-50e3-4d30-9753-4d0f23beee08",
   "metadata": {},
   "source": [
    "# AI Clinical Notes Scribe use-case \n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Analysis of Use-Case\n",
    "\n",
    "### **Business Goal**\n",
    "\n",
    "* Reduce clinician administrative burden\n",
    "* Improve accuracy of clinical documentation\n",
    "* Ensure compliance with medical record-keeping requirements\n",
    "\n",
    "### **System Decomposition**\n",
    "\n",
    "1. **Speech-to-Text System**\n",
    "\n",
    "   * Inputs: Audio from doctor–patient consultation\n",
    "   * Risks: Data capture, PHI exposure, model bias\n",
    "2. **Summarization & Structuring System (LLM layer)**\n",
    "\n",
    "   * Inputs: Transcripts\n",
    "   * Outputs: Structured clinical notes (SOAP, ICD-10/SNOMED tags)\n",
    "   * Risks: Hallucinations, ontology misalignment, overfitting to sensitive corpora\n",
    "   * *This is the main focus of the threat model.*\n",
    "3. **Review & Approval Interface**\n",
    "\n",
    "   * Inputs: Draft notes\n",
    "   * Outputs: Clinician-reviewed records\n",
    "   * Risks: Human error, insider threats, incomplete oversight\n",
    "4. **Integration & Storage System**\n",
    "\n",
    "   * Inputs: Approved notes\n",
    "   * Outputs: EHR records with coding/indexing\n",
    "   * Risks: Unauthorized access, improper integration, regulatory non-compliance\n",
    "\n",
    "### **Lifecycle Scope (Development / Training)**\n",
    "\n",
    "* Speech-to-Text: Acoustic/language model training on sensitive data\n",
    "* Summarization: Fine-tuning on clinical corpora, ICD-10/SNOMED ontologies\n",
    "\n",
    "### **Key Considerations**\n",
    "\n",
    "* No autonomous diagnosis/treatment recommendations\n",
    "* Strictly *summarization & structuring* role\n",
    "* Regulatory compliance (HIPAA, HITECH, ONC rules)\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Mermaid Diagram (System Flow)\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    %% === Actors ===\n",
    "    A[👩‍⚕️ Clinician] -->|Audio Input| B[🎙️ Speech-to-Text System]\n",
    "    A -->|Review & Approve| D[🖥️ Review & Approval Interface]\n",
    "\n",
    "    %% === Core System ===\n",
    "    B -->|Transcript| C[🧠 Summarization & Structuring System<br>LLM Layer]\n",
    "    C -->|Draft Notes| D\n",
    "    D -->|Approved Notes| E[📂 Integration & Storage System<br>EHR, Coding, Indexing]\n",
    "\n",
    "    %% === Boundaries ===\n",
    "    subgraph Scope[\"🔒 In-Scope AI Lifecycle\"]\n",
    "        B\n",
    "        C\n",
    "    end\n",
    "\n",
    "    subgraph OutOfScope[\"📋 Out-of-Scope Optional\"]\n",
    "        D\n",
    "        E\n",
    "    end\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ⚡ Next Step for Threat Modeling\n",
    "\n",
    "* From this diagram, we can apply **threat model vectors**:\n",
    "\n",
    "  * **STRIDE** (Spoofing, Tampering, Repudiation, Info Disclosure, DoS, Elevation of Privilege)\n",
    "  * **DASF 2.0 Risks** (Data Poisoning, Prompt Injection, Model Misuse, EHR Integration Risks)\n",
    "  * **MITRE ATLAS** / **MITRE ATT\\&CK for AI** mapping\n",
    "\n",
    "---\n",
    "\n",
    "Here’s we're **AI Clinical Notes Scribe** flow reworked with a **cohesive color palette** applied to each subsystem. I used our palette mapping to distinguish actors, in-scope AI systems, and optional/out-of-scope components.\n",
    "\n",
    "---\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    %% === Actors ===\n",
    "    A1[👩‍⚕️ Clinician] -->|Audio Input| B1[🎙️ Speech-to-Text System]\n",
    "    A1 -->|Review & Approve| D1[🖥️ Review & Approval Interface]\n",
    "\n",
    "    %% === Core System ===\n",
    "    B1 -->|Transcript| C1[🧠 Summarization & Structuring System<br>LLM Layer]\n",
    "    C1 -->|Draft Notes| D1\n",
    "    D1 -->|Approved Notes| D2[📂 Integration & Storage System<br>EHR, Coding, Indexing]\n",
    "\n",
    "    %% === Boundaries ===\n",
    "    subgraph Scope[\"🔒 In-Scope AI Lifecycle\"]\n",
    "        B1\n",
    "        C1\n",
    "    end\n",
    "\n",
    "    subgraph OutOfScope[\"📋 Out-of-Scope Optional\"]\n",
    "        D1\n",
    "        D2\n",
    "    end\n",
    "\n",
    "    %% === COLORS (from palette) ===\n",
    "    style A1 fill:#80cbc4,stroke:#00695c,stroke-width:2px,color:#000  \n",
    "    style B1 fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px,color:#000 \n",
    "    style C1 fill:#90caf9,stroke:#0d47a1,stroke-width:2px,color:#000 \n",
    "    style D1 fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000 \n",
    "    style D2 fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "✅ Now each block has a distinct color family:\n",
    "\n",
    "* **Teal (Clinician)** – human actors\n",
    "* **Red (Speech-to-Text)** – raw data capture (risk-heavy)\n",
    "* **Blue (LLM Summarization)** – main AI focus\n",
    "* **Purple (Review & Integration)** – downstream systems\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    %% === Actors ===\n",
    "    A1[👩‍⚕️ Clinician] -->|Audio Input| B1[🎙️ Speech-to-Text System]\n",
    "    A1 -->|Review & Approve| D1[🖥️ Review & Approval Interface]\n",
    "\n",
    "    %% === Core System ===\n",
    "    B1 -->|Transcript| C1[🧠 Summarization & Structuring System<br>LLM Layer]\n",
    "    C1 -->|Draft Notes| D1\n",
    "    D1 -->|Approved Notes| D2[📂 Integration & Storage System<br>EHR, Coding, Indexing]\n",
    "\n",
    "    %% === Boundaries ===\n",
    "    subgraph Scope[\"🔒 In-Scope AI Lifecycle\"]\n",
    "        B1\n",
    "        C1\n",
    "    end\n",
    "\n",
    "    subgraph OutOfScope[\"📋 Out-of-Scope Optional\"]\n",
    "        D1\n",
    "        D2\n",
    "    end\n",
    "\n",
    "    %% === COLORS (from palette) ===\n",
    "    style A1 fill:#80cbc4,stroke:#00695c,stroke-width:2px,color:#000  \n",
    "    style B1 fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px,color:#000 \n",
    "    style C1 fill:#90caf9,stroke:#0d47a1,stroke-width:2px,color:#000 \n",
    "    style D1 fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000 \n",
    "    style D2 fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "✨ Changes made:\n",
    "\n",
    "* Removed all **parentheses**\n",
    "* “LLM Layer” and “Out-of-Scope Optional” now display without `()`\n",
    "* Kept consistent color palette for readability\n",
    "\n",
    "---\n",
    "\n",
    "Let’s add an **AI Safety Classifier agent** into the pipeline. This ensures that the system flags unsafe content, PHI mis-capture, or hallucinated diagnoses *before* notes reach the clinician. It becomes a **safety and assurance checkpoint** between the Summarization/Structuring system and the Review Interface.\n",
    "\n",
    "Here’s the updated diagram with our palette, now including the **Safety Classifier**:\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    %% === Actors ===\n",
    "    A1[👩‍⚕️ Clinician] -->|Audio Input| B1[🎙️ Speech-to-Text System]\n",
    "    A1 -->|Review & Approve| D1[🖥️ Review & Approval Interface]\n",
    "\n",
    "    %% === Core System ===\n",
    "    B1 -->|Transcript| C1[🧠 Summarization & Structuring System<br>LLM Layer]\n",
    "    C1 -->|Draft Notes| S1[🛡️ AI Safety Classifier<br>Bias & Risk Filter]\n",
    "    S1 -->|Validated Notes| D1\n",
    "    D1 -->|Approved Notes| D2[📂 Integration & Storage System<br>EHR, Coding, Indexing]\n",
    "\n",
    "    %% === Boundaries ===\n",
    "    subgraph Scope[\"🔒 In-Scope AI Lifecycle\"]\n",
    "        B1\n",
    "        C1\n",
    "        S1\n",
    "    end\n",
    "\n",
    "    subgraph OutOfScope[\"📋 Out-of-Scope Optional\"]\n",
    "        D1\n",
    "        D2\n",
    "    end\n",
    "\n",
    "    %% === COLORS (from palette) ===\n",
    "    style A1 fill:#80cbc4,stroke:#00695c,stroke-width:2px,color:#000  \n",
    "    style B1 fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px,color:#000 \n",
    "    style C1 fill:#90caf9,stroke:#0d47a1,stroke-width:2px,color:#000 \n",
    "    style S1 fill:#ffe082,stroke:#ff6f00,stroke-width:2px,color:#000 \n",
    "    style D1 fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000 \n",
    "    style D2 fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔑 What Changed\n",
    "\n",
    "* **New node**: 🛡️ **AI Safety Classifier**\n",
    "\n",
    "  * Role: Detect hallucinations, ensure no diagnosis slips in, flag anomalies, enforce compliance (HIPAA, PHI redaction).\n",
    "  * Positioned **between Summarization and Review**.\n",
    "* **New palette color (Amber)** for safety layer → stands out as a trust/control checkpoint.\n",
    "\n",
    "---\n",
    "\n",
    "👉 Next, we can enrich this by adding:\n",
    "\n",
    "* **Threat modeling overlay**: STRIDE + DASF mapped to each box.\n",
    "* **Multiple agents**: e.g., a **Compliance Agent** (HIPAA auditor) alongside the Safety Classifier.\n",
    "\n",
    "if we’re building toward a **threat model vector + governance framework**, we need to think in terms of the **AI lifecycle** and explicitly track **artifacts**:\n",
    "\n",
    "* **Model Cards** → document the purpose, limitations, benchmarks, risks of each model\n",
    "* **Dataset Cards** → describe sources, curation, bias, privacy, compliance metadata\n",
    "* **Agent Cards** → capture decision roles, safety checks, audit functions across the pipeline\n",
    "\n",
    "Here’s how that looks for our **AI Clinical Notes Scribe** use-case:\n",
    "\n",
    "---\n",
    "\n",
    "## 🔄 AI Lifecycle Mapped to Artifacts\n",
    "\n",
    "### **1. Data Collection & Preprocessing**\n",
    "\n",
    "* **Dataset Cards**:\n",
    "\n",
    "  * Clinical audio (doctor–patient conversations)\n",
    "  * Clinical text corpora (SOAP notes, ICD-10, SNOMED, medical ontologies)\n",
    "  * Compliance metadata: HIPAA, de-identification process, annotation protocols\n",
    "\n",
    "### **2. Model Development / Training**\n",
    "\n",
    "* **Model Cards**:\n",
    "\n",
    "  * **Speech-to-Text Model** – tuned on clinical audio, note accuracy/WER, risks of bias\n",
    "  * **Summarization Model (LLM Layer)** – fine-tuned on SOAP structure, ICD/SNOMED\n",
    "  * **Safety Classifier** – adversarially tested against hallucinations, unsafe completions\n",
    "\n",
    "### **3. Deployment & Orchestration**\n",
    "\n",
    "* **Agent Cards**:\n",
    "\n",
    "  * **Safety Agent** 🛡️ – filters hallucinations, detects PHI miscapture\n",
    "  * **Compliance Agent** 📜 – ensures HIPAA adherence, records audit logs\n",
    "  * **Workflow Agent** 🔄 – orchestrates movement: Audio → Transcript → Notes → EHR\n",
    "\n",
    "### **4. Human-in-the-Loop**\n",
    "\n",
    "* Clinician review interface documented as **Agent Card** (Human Oversight Agent)\n",
    "* Track clinician feedback loops for retraining → linked back to Dataset Cards\n",
    "\n",
    "### **5. Monitoring & Governance**\n",
    "\n",
    "* **Model Cards** updated with post-deployment metrics (accuracy drift, bias shifts)\n",
    "* **Dataset Cards** track dataset lineage, refresh cycles, augmentation history\n",
    "* **Agent Cards** ensure policy enforcement (RBAC, audit trails, explainability)\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Conceptual Diagram (Lifecycle + Cards)\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "\n",
    "    subgraph Data[\"📂 Data Collection\"]\n",
    "        D1[Clinical Audio Dataset<br>Dataset Card]\n",
    "        D2[Clinical Text Corpora<br>Dataset Card]\n",
    "    end\n",
    "\n",
    "    subgraph Models[\"🧠 Model Development\"]\n",
    "        M1[Speech-to-Text Model<br>Model Card]\n",
    "        M2[Summarization Model<br>Model Card]\n",
    "        M3[Safety Classifier Model<br>Model Card]\n",
    "    end\n",
    "\n",
    "    subgraph Agents[\"🤖 Agent Layer\"]\n",
    "        A1[Safety Agent<br>Agent Card]\n",
    "        A2[Compliance Agent<br>Agent Card]\n",
    "        A3[Workflow Agent<br>Agent Card]\n",
    "        A4[Human Oversight Agent<br>Agent Card]\n",
    "    end\n",
    "\n",
    "    subgraph Deployment[\"🚀 Deployment & Integration\"]\n",
    "        UI[Review Interface]\n",
    "        EHR[EHR Integration]\n",
    "    end\n",
    "\n",
    "    %% Flows\n",
    "    D1 --> M1\n",
    "    D2 --> M2\n",
    "    M1 --> M2\n",
    "    M2 --> A1\n",
    "    A1 --> A2\n",
    "    A2 --> UI\n",
    "    UI --> A4\n",
    "    A4 --> EHR\n",
    "    A3 --> M1\n",
    "    A3 --> M2\n",
    "    A3 --> UI\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Why This Matters\n",
    "\n",
    "* **Traceability**: Every model, dataset, and agent is explicitly documented (cards).\n",
    "* **Governance**: Each phase maps to **assurance artifacts** wecan align to DASF, NIST AI RMF, HIPAA.\n",
    "* **Threat Modeling**: We can overlay STRIDE/DASF threats **per card** (e.g., “Dataset Poisoning → Dataset Card”, “Prompt Injection → Summarization Model Card”).\n",
    "\n",
    "---\n",
    "\n",
    "the lifecycle diagram will pop more once we apply we're **color palette** consistently across **datasets, models, agents, and deployment nodes**. I’ll extend we're earlier palette and add new shades for variety:\n",
    "\n",
    "* **Teal** → Data (datasets)\n",
    "* **Red** → Models (AI components, core risk)\n",
    "* **Blue** → Agents (safety, compliance, workflow, human oversight)\n",
    "* **Purple** → Deployment & Integration\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Diagram with Color Palette\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "\n",
    "    subgraph Data[\"📂 Data Collection\"]\n",
    "        D1[Clinical Audio Dataset<br>Dataset Card]\n",
    "        D2[Clinical Text Corpora<br>Dataset Card]\n",
    "    end\n",
    "\n",
    "    subgraph Models[\"🧠 Model Development\"]\n",
    "        M1[Speech-to-Text Model<br>Model Card]\n",
    "        M2[Summarization Model<br>Model Card]\n",
    "        M3[Safety Classifier Model<br>Model Card]\n",
    "    end\n",
    "\n",
    "    subgraph Agents[\"🤖 Agent Layer\"]\n",
    "        A1[Safety Agent<br>Agent Card]\n",
    "        A2[Compliance Agent<br>Agent Card]\n",
    "        A3[Workflow Agent<br>Agent Card]\n",
    "        A4[Human Oversight Agent<br>Agent Card]\n",
    "    end\n",
    "\n",
    "    subgraph Deployment[\"🚀 Deployment & Integration\"]\n",
    "        UI[Review Interface]\n",
    "        EHR[EHR Integration]\n",
    "    end\n",
    "\n",
    "    %% Flows\n",
    "    D1 --> M1\n",
    "    D2 --> M2\n",
    "    M1 --> M2\n",
    "    M2 --> A1\n",
    "    A1 --> A2\n",
    "    A2 --> UI\n",
    "    UI --> A4\n",
    "    A4 --> EHR\n",
    "    A3 --> M1\n",
    "    A3 --> M2\n",
    "    A3 --> UI\n",
    "\n",
    "    %% === COLORS (palette applied) ===\n",
    "    %% Data (Teal)\n",
    "    style D1 fill:#80cbc4,stroke:#00695c,stroke-width:2px,color:#000\n",
    "    style D2 fill:#80cbc4,stroke:#00695c,stroke-width:2px,color:#000\n",
    "\n",
    "    %% Models (Red)\n",
    "    style M1 fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px,color:#000\n",
    "    style M2 fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px,color:#000\n",
    "    style M3 fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px,color:#000\n",
    "\n",
    "    %% Agents (Blue)\n",
    "    style A1 fill:#90caf9,stroke:#0d47a1,stroke-width:2px,color:#000\n",
    "    style A2 fill:#90caf9,stroke:#0d47a1,stroke-width:2px,color:#000\n",
    "    style A3 fill:#90caf9,stroke:#0d47a1,stroke-width:2px,color:#000\n",
    "    style A4 fill:#90caf9,stroke:#0d47a1,stroke-width:2px,color:#000\n",
    "\n",
    "    %% Deployment (Purple)\n",
    "    style UI fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000\n",
    "    style EHR fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "✅ Now each layer has a **distinct, reusable color code**:\n",
    "\n",
    "* **Teal** = Data sources & dataset cards\n",
    "* **Red** = AI models (sensitive/risk surfaces)\n",
    "* **Blue** = Agents (trust, safety, compliance)\n",
    "* **Purple** = Deployment & integration endpoints\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7519ad4-f20c-49bb-9179-435ddcc206ed",
   "metadata": {},
   "source": [
    "\n",
    "1. **User-Interaction Diagram** → shows how clinicians, patients, and the system interact step by step (front-end workflow).\n",
    "2. **Systems Diagram** → shows how the backend runs on Linux Foundation infrastructure + open-source tools (aligned with we're Kubeflow/MLflow/DataOps stack style).\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 👥 User-Interaction Diagram\n",
    "\n",
    "This diagram traces how a clinician and system interact during a consultation.\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant P as 🧑‍⚕️ Clinician\n",
    "    participant S as 🎙️ Speech-to-Text\n",
    "    participant L as 🧠 Summarization (LLM)\n",
    "    participant G as 🛡️ Safety Classifier\n",
    "    participant R as 🖥️ Review Interface\n",
    "    participant E as 📂 EHR System\n",
    "\n",
    "    P->>S: Dictates consultation (audio)\n",
    "    S->>L: Transcript text\n",
    "    L->>G: Draft clinical notes\n",
    "    G->>R: Validated notes (no hallucinations/unsafe output)\n",
    "    R->>P: Clinician reviews/edits notes\n",
    "    P->>E: Approves and saves to EHR\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 🖧 Systems Diagram (Linux Foundation + Open Source)\n",
    "\n",
    "Here’s how this could run on an **open-source control plane**, showing tools + integration points.\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "\n",
    "    %% Data Layer\n",
    "    subgraph DataOps[\"📂 DataOps Layer\"]\n",
    "        DA[Audio Storage<br>MinIO / S3]\n",
    "        DT[Transcript DB<br>PostgreSQL + pgvector]\n",
    "    end\n",
    "\n",
    "    %% AI/ML Layer\n",
    "    subgraph MLOps[\"🧠 MLOps Control Plane\"]\n",
    "        STT[Speech-to-Text<br>Kaldi / wav2vec2]\n",
    "        SUM[Summarization LLM<br>KServe + Triton]\n",
    "        SAFE[Safety Classifier<br>ONNX / HuggingFace]\n",
    "    end\n",
    "\n",
    "    %% Governance & Workflow\n",
    "    subgraph Governance[\"🔒 Governance + Orchestration\"]\n",
    "        WF[Workflow Orchestration<br>Kubeflow Pipelines]\n",
    "        LOG[Audit Logs<br>OpenSearch]\n",
    "        POL[Policy Enforcement<br>OPA / Kyverno]\n",
    "    end\n",
    "\n",
    "    %% Endpoints\n",
    "    subgraph Endpoints[\"🚀 Deployment & Integration\"]\n",
    "        UI[Review UI<br>Streamlit / Angular]\n",
    "        EHR[EHR Integration<br>FHIR APIs]\n",
    "    end\n",
    "\n",
    "    %% Flows\n",
    "    DA --> STT\n",
    "    STT --> DT\n",
    "    STT --> SUM\n",
    "    SUM --> SAFE\n",
    "    SAFE --> UI\n",
    "    UI --> EHR\n",
    "    WF --> STT\n",
    "    WF --> SUM\n",
    "    WF --> SAFE\n",
    "    LOG --> POL\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🎨 Color Palette \n",
    "\n",
    "To match our earlier diagrams:\n",
    "\n",
    "* **Teal (#80cbc4)** → DataOps Layer (datasets, storage)\n",
    "* **Red (#ef9a9a)** → Models (STT, LLM, Safety Classifier)\n",
    "* **Blue (#90caf9)** → Agents / Orchestration\n",
    "* **Purple (#b39ddb)** → Deployment / Integration\n",
    "\n",
    "---\n",
    "\n",
    "⚡ With these two diagrams, we now have:\n",
    "\n",
    "* A **front-end view** (user-interaction sequence).\n",
    "* A **back-end view** (Linux Foundation infra + OSS stack).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7688f4eb-f432-4135-bbf3-6165eb77c0ff",
   "metadata": {},
   "source": [
    "* A **threat model** identifies potential adversarial or failure risks.\n",
    "* A **threat vector model** extends that by explicitly mapping **where and how attacks or failures can enter the system** (data paths, model layers, interfaces, integrations).\n",
    "* In the AI/ML domain, this usually aligns with **STRIDE + AI-specific risk catalogs** (e.g., DASF 2.0, MITRE ATLAS).\n",
    "\n",
    "---\n",
    "\n",
    "# 🛡️ AI Threat Vector Model for Clinical Notes Scribe\n",
    "\n",
    "I’ll map **risks + controls** across **data, model, agent, deployment** layers.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. DataOps Layer (Data Collection & Processing)\n",
    "\n",
    "**Threat Vectors:**\n",
    "\n",
    "* **Data Poisoning** → adversarial inputs (malicious patient recordings, mislabeled transcripts).\n",
    "* **PHI Exposure** → captured audio/transcripts leaked outside HIPAA boundaries.\n",
    "* **Ontology Drift** → ICD-10/SNOMED taxonomy updates not reflected in training data.\n",
    "\n",
    "**Controls:**\n",
    "\n",
    "* ✅ **Dataset Cards** → document source, curation, PHI handling.\n",
    "* ✅ **De-identification** → automated PHI scrubbing pipelines.\n",
    "* ✅ **Access Control** → MinIO/S3 encryption, RBAC via Vault.\n",
    "* ✅ **Data Validation** → schema checks, anomaly detection before ingestion.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Model Layer (STT, Summarization LLM, Safety Classifier)\n",
    "\n",
    "**Threat Vectors:**\n",
    "\n",
    "* **Model Poisoning** → training manipulation (e.g., biasing transcription against accents).\n",
    "* **Prompt Injection** → malicious input instructions from transcribed speech.\n",
    "* **Hallucination** → fabricated diagnoses in summaries.\n",
    "* **Overfitting/Leaking** → memorization of PHI, risk of leakage.\n",
    "\n",
    "**Controls:**\n",
    "\n",
    "* ✅ **Model Cards** → risks, benchmarks, limitations.\n",
    "* ✅ **Differential Privacy** → to prevent PHI memorization.\n",
    "* ✅ **Prompt Guardrails** → input moderation before LLM.\n",
    "* ✅ **Adversarial Testing** → simulate hostile queries, accent variance, ontology perturbations.\n",
    "* ✅ **Ensemble Safety Classifier** → bias detection, hallucination detection.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Agent Layer (Safety, Compliance, Workflow, Human Oversight)\n",
    "\n",
    "**Threat Vectors:**\n",
    "\n",
    "* **Bypass Attacks** → attempts to skip moderation agents.\n",
    "* **Insider Threats** → misuse of override controls by clinical staff.\n",
    "* **Weak Auditability** → lack of traceability on agent decisions.\n",
    "\n",
    "**Controls:**\n",
    "\n",
    "* ✅ **Agent Cards** → document safety, compliance, workflow roles.\n",
    "* ✅ **RBAC + MFA** → strict role-based permissions for overrides.\n",
    "* ✅ **Audit Trails** → all decisions logged in OpenSearch.\n",
    "* ✅ **Explainability Hooks** → classifier outputs must justify rejections/flags.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Deployment & Integration Layer (EHR + UI)\n",
    "\n",
    "**Threat Vectors:**\n",
    "\n",
    "* **Unauthorized Access** → exposed FHIR APIs.\n",
    "* **Improper Integration** → data misaligned with EHR fields.\n",
    "* **DoS Risks** → overloading API endpoints with queries.\n",
    "* **Human Error** → clinician approving unsafe drafts.\n",
    "\n",
    "**Controls:**\n",
    "\n",
    "* ✅ **Zero Trust Access** → API authz with OAuth2 + mTLS.\n",
    "* ✅ **EHR Validation** → schema conformance checks (FHIR validators).\n",
    "* ✅ **Rate Limiting** → API gateways (Kong/Envoy).\n",
    "* ✅ **Mandatory HITL Review** → clinician approval enforced, no auto-submission.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Governance & Monitoring\n",
    "\n",
    "**Threat Vectors:**\n",
    "\n",
    "* **Model Drift** → accuracy degrading silently.\n",
    "* **Compliance Drift** → HIPAA/NIST/ONC rules change, system not updated.\n",
    "* **Silent Failures** → logs not monitored, anomalies undetected.\n",
    "\n",
    "**Controls:**\n",
    "\n",
    "* ✅ **Continuous Monitoring** → MLflow/Kubeflow metrics, Grafana dashboards.\n",
    "* ✅ **Policy Enforcement** → OPA/Kyverno for Kubernetes workloads.\n",
    "* ✅ **Compliance Audits** → periodic HIPAA/NIST RMF alignment.\n",
    "* ✅ **Red Teaming** → simulated adversarial misuse.\n",
    "\n",
    "---\n",
    "\n",
    "# 📊 Conceptual Threat Vector Overlay\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    D[📂 DataOps Layer] --> M[🧠 Models]\n",
    "    M --> A[🤖 Agents]\n",
    "    A --> U[🖥️ UI / EHR Integration]\n",
    "    U --> G[🔒 Governance & Monitoring]\n",
    "\n",
    "    %% Risks\n",
    "    D -->|Risk: Data Poisoning, PHI Leakage| M\n",
    "    M -->|Risk: Prompt Injection, Hallucination| A\n",
    "    A -->|Risk: Bypass, Insider Threat| U\n",
    "    U -->|Risk: Unauthorized Access, DoS| G\n",
    "    G -->|Risk: Model/Compliance Drift| D\n",
    "\n",
    "    %% Controls\n",
    "    style D fill:#80cbc4,stroke:#00695c,stroke-width:2px\n",
    "    style M fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px\n",
    "    style A fill:#90caf9,stroke:#0d47a1,stroke-width:2px\n",
    "    style U fill:#b39ddb,stroke:#4527a0,stroke-width:2px\n",
    "    style G fill:#ffe082,stroke:#ff6f00,stroke-width:2px\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# ✅ Takeaway\n",
    "\n",
    "* We**are** building an **AI Threat Vector Model** → it’s a **layered map** of risks + controls across **data, models, agents, deployment, governance**.\n",
    "* This makes it possible to overlay **STRIDE**, **DASF 2.0**, and **MITRE ATLAS** to get a **full-spectrum risk catalog**.\n",
    "* Next logical step:\n",
    "\n",
    "  * Build a **risk-control matrix table** (Risk → Attack Vector → Control Mapping).\n",
    "  * Assign **severity scores** (Likelihood × Impact) → prioritize mitigations.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d3bf4-f21b-4d2c-bdc5-2946461215a3",
   "metadata": {},
   "source": [
    "Let’s build the **Risk–Control Matrix** for we're **AI Clinical Notes Scribe Threat Vector Model**.\n",
    "This table captures **Risks → Attack Vectors → Recommended Controls → Severity (Likelihood × Impact)** so wecan prioritize mitigations.\n",
    "\n",
    "---\n",
    "\n",
    "# 🛡️ AI Clinical Notes Scribe – Threat Vector Risk–Control Matrix\n",
    "\n",
    "| **Layer**      | **Risk / Threat Vector**       | **Attack Surface**              | **Controls (Mitigations)**                                                       | **Severity** |\n",
    "| -------------- | ------------------------------ | ------------------------------- | -------------------------------------------------------------------------------- | ------------ |\n",
    "| **DataOps**    | Data Poisoning                 | Malicious audio / transcripts   | Data validation pipelines, anomaly detection, schema enforcement, human curation | **High**     |\n",
    "|                | PHI Leakage                    | Audio / transcript storage      | MinIO/S3 encryption, RBAC, Vault key mgmt, de-identification                     | **Critical** |\n",
    "|                | Ontology Drift                 | ICD/SNOMED taxonomy changes     | Dataset versioning, ontology monitoring, retraining triggers                     | **Medium**   |\n",
    "| **Models**     | Prompt Injection               | Transcript-to-LLM inputs        | Input guardrails, regex/pattern filters, adversarial prompt testing              | **High**     |\n",
    "|                | Hallucination                  | Summarization outputs           | Safety classifier, grounding to ICD/SNOMED, RAG context enforcement              | **Critical** |\n",
    "|                | Model Poisoning                | Fine-tuning pipeline            | Signed datasets, reproducible training, differential privacy                     | **High**     |\n",
    "|                | Overfitting (PHI Memorization) | LLM embeddings                  | Differential privacy, regularization, red-teaming                                | **High**     |\n",
    "| **Agents**     | Bypass Attacks                 | Safety/compliance agents        | Mandatory policy checkpoints, RBAC enforced pipelines                            | **Medium**   |\n",
    "|                | Insider Threats                | Clinician/staff overrides       | RBAC + MFA, audit trails, least-privilege policies                               | **High**     |\n",
    "|                | Weak Auditability              | Agent decisions not logged      | OpenSearch immutable audit logs, explainability hooks                            | **Medium**   |\n",
    "| **Deployment** | Unauthorized Access            | FHIR/EHR APIs                   | OAuth2 + mTLS, zero trust networking, API gateways                               | **Critical** |\n",
    "|                | Improper Integration           | EHR mapping                     | FHIR schema validators, integration tests, EHR conformance checks                | **High**     |\n",
    "|                | DoS Attacks                    | API endpoints                   | Rate limiting, auto-scaling, WAF                                                 | **Medium**   |\n",
    "|                | Human Error                    | Clinician approves unsafe draft | HITL enforced, UI risk flags, safety classifier explainability                   | **Medium**   |\n",
    "| **Governance** | Model Drift                    | Accuracy degradation            | Continuous monitoring, retraining alerts, MLflow drift tracking                  | **High**     |\n",
    "|                | Compliance Drift               | HIPAA/NIST/ONC changes          | Policy mapping to NIST AI RMF, regular compliance audits                         | **Critical** |\n",
    "|                | Silent Failures                | Unmonitored logs/alerts         | Grafana dashboards, anomaly detection, alert routing                             | **High**     |\n",
    "\n",
    "---\n",
    "\n",
    "# 🔑 Observations\n",
    "\n",
    "* **Critical Risks** → PHI leakage, hallucinations, unauthorized access, compliance drift.\n",
    "  → These must have **multiple overlapping controls** (defense-in-depth).\n",
    "* **High Risks** → Data poisoning, model poisoning, overfitting, drift.\n",
    "  → Require continuous monitoring + strong MLOps discipline.\n",
    "* **Medium Risks** → Ontology drift, bypass attacks, auditability gaps, DoS, human error.\n",
    "  → Important, but secondary to Critical/High risks.\n",
    "\n",
    "---\n",
    "\n",
    "# 📊 Next Step\n",
    "\n",
    "We can extend this into a **Threat Modeling Matrix** by explicitly **tagging each risk** with:\n",
    "\n",
    "* **STRIDE** (Spoofing, Tampering, Repudiation, Info Disclosure, DoS, Elevation of Privilege)\n",
    "* **DASF 2.0 Risks** (e.g., Data Poisoning, Prompt Injection, Model Misuse, EHR Integration Risk)\n",
    "* **MITRE ATLAS Techniques** (e.g., TA0040 Model Evasion, TA0029 Data Manipulation)\n",
    "* **[IBM AI Risk ATLAS](https://www.ibm.com/docs/en/watsonx/saas?topic=ai-risk-atlas)**\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ec0a1-6f9c-419b-b43a-91dec12e0133",
   "metadata": {},
   "source": [
    "now we’ll **enrich we're Threat Vector Risk–Control Matrix** by mapping each risk to:\n",
    "\n",
    "1. **STRIDE** → Classic software threat modeling categories.\n",
    "2. **DASF 2.0** → AI/ML–specific risk families (Data poisoning, Prompt injection, Model misuse, etc.).\n",
    "3. **MITRE ATLAS** → AI adversary tactics & techniques.\n",
    "4. **NIST 800-53 Rev 5 (and 53B baselines)** → Security & privacy controls to enforce compliance.\n",
    "\n",
    "This makes our **AI Clinical Notes Scribe Threat Model** fully aligned with **federal compliance, AI governance, and adversarial ML frameworks**.\n",
    "\n",
    "---\n",
    "\n",
    "# 🛡️ AI Clinical Notes Scribe – Threat Vector Matrix (with STRIDE, DASF, MITRE, NIST 800-53 Rev 5)\n",
    "\n",
    "| **Layer**      | **Risk / Threat Vector**       | **STRIDE**                  | **DASF 2.0**                      | **MITRE ATLAS**                         | **NIST 800-53 Rev 5**                                                                        | **Controls**                                 |\n",
    "| -------------- | ------------------------------ | --------------------------- | --------------------------------- | --------------------------------------- | -------------------------------------------------------------------------------------------- | -------------------------------------------- |\n",
    "| **DataOps**    | Data Poisoning                 | Tampering                   | Data Integrity / Poisoning        | TA0029 – Data Manipulation              | SI-3 (Malicious Code Protection), SI-10 (Info Input Validation), SA-11 (Dev Testing)         | Data validation pipelines, anomaly detection |\n",
    "|                | PHI Leakage                    | Info Disclosure             | Privacy Leakage                   | TA0040 – Model Evasion                  | AC-3 (Access Enforcement), SC-28 (Data at Rest Encryption), SC-13 (Cryptographic Protection) | Encryption, RBAC, de-ID                      |\n",
    "|                | Ontology Drift                 | Tampering                   | Model Misalignment                | TA0022 – Supply Chain Manipulation      | SA-10 (Developer Config Mgmt), CM-2 (Baseline Config), CA-7 (Continuous Monitoring)          | Dataset versioning, retraining               |\n",
    "| **Models**     | Prompt Injection               | Tampering                   | Prompt Injection                  | TA0010 – Evasion via Input Manipulation | SI-10 (Input Validation), SC-23 (Session Authenticity), RA-5 (Vulnerability Scanning)        | Guardrails, input filters                    |\n",
    "|                | Hallucination                  | Tampering / Info Disclosure | Hallucination / Unsafe Generation | TA0042 – Model Output Manipulation      | SA-11 (Testing), SI-4 (Monitoring), SR-11 (Supply Chain Protection)                          | Safety classifier, ontology grounding        |\n",
    "|                | Model Poisoning                | Tampering                   | Training Data Poisoning           | TA0029 – Data Manipulation              | SA-12 (Supply Chain Integrity), RA-5, SI-7 (Software Integrity)                              | Signed datasets, reproducible training       |\n",
    "|                | Overfitting (PHI memorization) | Info Disclosure             | Privacy Leakage                   | TA0040 – Model Evasion                  | PL-8 (Privacy Records), SC-28, SI-12 (Information Handling)                                  | DP-SGD, regularization, red-teaming          |\n",
    "| **Agents**     | Bypass Attacks                 | Elevation of Privilege      | Model Misuse / Policy Bypass      | TA0040 – Model Evasion                  | AC-6 (Least Privilege), IA-2 (MFA), AU-12 (Audit Logs)                                       | Enforced checkpoints, RBAC                   |\n",
    "|                | Insider Threats                | Spoofing / Elevation        | Model Misuse                      | TA0017 – Insider Threat                 | AC-2 (Account Mgmt), PS-3 (Personnel Screening), AU-6 (Audit Review)                         | RBAC, MFA, least privilege                   |\n",
    "|                | Weak Auditability              | Repudiation                 | Auditability Gap                  | TA0040 – Model Evasion                  | AU-2 (Event Logging), AU-8 (Timestamp), AU-12 (Audit Generation)                             | Immutable logs, explainability hooks         |\n",
    "| **Deployment** | Unauthorized Access            | Spoofing / Elevation        | Unauthorized Access               | TA0001 – Initial Access                 | AC-3, AC-17 (Remote Access), SC-12 (Crypto Key Estab)                                        | OAuth2, mTLS, API gateways                   |\n",
    "|                | Improper Integration           | Tampering                   | EHR Integration Risk              | TA0022 – Supply Chain                   | SA-10, SI-10, IA-5 (Authenticator Mgmt)                                                      | FHIR validators, integration testing         |\n",
    "|                | DoS Attacks                    | DoS                         | Availability Attacks              | TA0041 – Resource Consumption           | SC-5 (Denial-of-Service Protection), SC-6 (Resource Priority)                                | Rate limiting, auto-scaling, WAF             |\n",
    "|                | Human Error (unsafe approval)  | Repudiation                 | HITL Failure                      | TA0042 – Output Manipulation            | AT-2 (Awareness Training), AC-2, AU-12                                                       | HITL enforced, UI risk flags                 |\n",
    "| **Governance** | Model Drift                    | Tampering                   | Model Misuse                      | TA0040 – Model Evasion                  | CA-7 (Monitoring), SA-11, PM-9 (Risk Mgmt Strategy)                                          | Drift detection, retraining                  |\n",
    "|                | Compliance Drift               | Repudiation                 | Regulatory Non-Compliance         | TA0011 – Policy Bypass                  | PL-2 (Privacy Program), PL-8, CA-2 (Assessments), PM-9                                       | Regulatory mapping, audits                   |\n",
    "|                | Silent Failures                | DoS / Repudiation           | Monitoring Gaps                   | TA0040 – Model Evasion                  | SI-4 (System Monitoring), IR-4 (Incident Handling), AU-6                                     | Grafana dashboards, anomaly detection        |\n",
    "\n",
    "---\n",
    "\n",
    "# 🔑 Key Insights\n",
    "\n",
    "* **Critical intersections**:\n",
    "\n",
    "  * **Hallucinations + PHI memorization** → map directly to **HIPAA violations** (PL-8, SC-28).\n",
    "  * **Unauthorized Access** → maps to **Access Controls (AC family)**.\n",
    "  * **Compliance Drift** → maps to **Program Management (PM, PL families)**, often ignored in ML pipelines.\n",
    "\n",
    "* **Value of mapping**:\n",
    "\n",
    "  * Wecan now **prove coverage** to auditors by saying: *“This hallucination risk maps to STRIDE Tampering, DASF Hallucination, MITRE ATLAS TA0042, and NIST SA-11 + SI-4.”*\n",
    "  * This ties **AI threat modeling** directly to **federal compliance frameworks** (NIST RMF / FedRAMP).\n",
    "\n",
    "---\n",
    "\n",
    "✅ With this, we now have a **living AI Threat Vector Model** for we're Clinical Notes Scribe use case — cross-referenced to STRIDE, DASF 2.0, MITRE ATLAS, and NIST 800-53 Rev 5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67d288-756e-4836-8d18-d67455050c17",
   "metadata": {},
   "source": [
    "let’s turn the **Risk–Control Matrix** into a **visual Threat Vector Overlay Diagram**.\n",
    "This way wecan walk auditors, engineers, and clinicians through the **entire threat landscape**, showing **where risks live**, which **STRIDE category** they fall under, and which **NIST 800-53 Rev 5 control family** mitigates them.\n",
    "\n",
    "---\n",
    "\n",
    "# 📊 Threat Vector Overlay\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "\n",
    "    %% === Layers ===\n",
    "    subgraph DataOps[\"📂 DataOps Layer\"]\n",
    "        D1[Data Poisoning<br>STRIDE: Tampering<br>NIST: SI, SA]\n",
    "        D2[PHI Leakage<br>STRIDE: Info Disclosure<br>NIST: AC, SC, PL]\n",
    "        D3[Ontology Drift<br>STRIDE: Tampering<br>NIST: CM, SA, CA]\n",
    "    end\n",
    "\n",
    "    subgraph Models[\"🧠 Models\"]\n",
    "        M1[Prompt Injection<br>STRIDE: Tampering<br>NIST: SI, SC, RA]\n",
    "        M2[Hallucination<br>STRIDE: Tampering/Disclosure<br>NIST: SA, SI, SR]\n",
    "        M3[Model Poisoning<br>STRIDE: Tampering<br>NIST: SA, SI]\n",
    "        M4[Overfitting / PHI Mem.<br>STRIDE: Info Disclosure<br>NIST: PL, SC, SI]\n",
    "    end\n",
    "\n",
    "    subgraph Agents[\"🤖 Agent Layer\"]\n",
    "        A1[Bypass Attacks<br>STRIDE: Elevation<br>NIST: AC, IA]\n",
    "        A2[Insider Threats<br>STRIDE: Spoofing/Elevation<br>NIST: AC, PS, AU]\n",
    "        A3[Weak Auditability<br>STRIDE: Repudiation<br>NIST: AU]\n",
    "    end\n",
    "\n",
    "    subgraph Deployment[\"🚀 Deployment & Integration\"]\n",
    "        U1[Unauthorized Access<br>STRIDE: Spoofing/Elevation<br>NIST: AC, SC]\n",
    "        U2[Improper Integration<br>STRIDE: Tampering<br>NIST: SA, SI, IA]\n",
    "        U3[DoS Attacks<br>STRIDE: DoS<br>NIST: SC]\n",
    "        U4[Human Error<br>STRIDE: Repudiation<br>NIST: AT, AC, AU]\n",
    "    end\n",
    "\n",
    "    subgraph Governance[\"🔒 Governance & Monitoring\"]\n",
    "        G1[Model Drift<br>STRIDE: Tampering<br>NIST: CA, SA, PM]\n",
    "        G2[Compliance Drift<br>STRIDE: Repudiation<br>NIST: PL, CA, PM]\n",
    "        G3[Silent Failures<br>STRIDE: DoS/Repudiation<br>NIST: SI, IR, AU]\n",
    "    end\n",
    "\n",
    "    %% === Flows ===\n",
    "    D1 --> M1\n",
    "    D2 --> M2\n",
    "    D3 --> M3\n",
    "    M1 --> A1\n",
    "    M2 --> A2\n",
    "    M3 --> A3\n",
    "    A1 --> U1\n",
    "    A2 --> U2\n",
    "    A3 --> U4\n",
    "    U1 --> G1\n",
    "    U2 --> G2\n",
    "    U3 --> G3\n",
    "    U4 --> G1\n",
    "\n",
    "    %% === Color Coding ===\n",
    "    style D1 fill:#80cbc4,stroke:#00695c,stroke-width:2px,color:#000\n",
    "    style D2 fill:#80cbc4,stroke:#00695c,stroke-width:2px,color:#000\n",
    "    style D3 fill:#80cbc4,stroke:#00695c,stroke-width:2px,color:#000\n",
    "\n",
    "    style M1 fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px,color:#000\n",
    "    style M2 fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px,color:#000\n",
    "    style M3 fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px,color:#000\n",
    "    style M4 fill:#ef9a9a,stroke:#b71c1c,stroke-width:2px,color:#000\n",
    "\n",
    "    style A1 fill:#90caf9,stroke:#0d47a1,stroke-width:2px,color:#000\n",
    "    style A2 fill:#90caf9,stroke:#0d47a1,stroke-width:2px,color:#000\n",
    "    style A3 fill:#90caf9,stroke:#0d47a1,stroke-width:2px,color:#000\n",
    "\n",
    "    style U1 fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000\n",
    "    style U2 fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000\n",
    "    style U3 fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000\n",
    "    style U4 fill:#b39ddb,stroke:#4527a0,stroke-width:2px,color:#000\n",
    "\n",
    "    style G1 fill:#ffe082,stroke:#ff6f00,stroke-width:2px,color:#000\n",
    "    style G2 fill:#ffe082,stroke:#ff6f00,stroke-width:2px,color:#000\n",
    "    style G3 fill:#ffe082,stroke:#ff6f00,stroke-width:2px,color:#000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 🔑 How to Use\n",
    "\n",
    "* Each **node** = Risk.\n",
    "* Annotated with **STRIDE category** + **NIST family (AC, SC, SI, etc.)**.\n",
    "* **Color palette** matches we're AI/MLOps diagrams:\n",
    "\n",
    "  * Teal → DataOps\n",
    "  * Red → Models\n",
    "  * Blue → Agents\n",
    "  * Purple → Deployment\n",
    "  * Amber → Governance\n",
    "\n",
    "This makes it clear for **engineers** (who see the stack) and **auditors** (who see the controls).\n",
    "\n",
    "---\n",
    "\n",
    "✅ Now we’ve got a **visual Threat Vector Overlay** for we're **AI Clinical Notes Scribe use case**, tied directly into **NIST 800-53 Rev 5 controls**, **STRIDE**, and **AI-specific risks**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61531b08-8bf9-450f-b02d-b8b35ec7ca6e",
   "metadata": {},
   "source": [
    "# Expanded master crosswalk to cover the full set of risks across all four frameworks:\n",
    "\n",
    "* **STRIDE**\n",
    "* **DASF 2.0**\n",
    "* **MITRE ATLAS**\n",
    "* **IBM AI Risk Atlas**\n",
    "* **NIST 800-53 Rev 5**\n",
    "\n",
    "so we now have a **complete catalog of risks** for we're Clinical Notes Scribe pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "# 🛡️ Expanded Threat Vector Risk Catalog\n",
    "\n",
    "### **A. DataOps Layer**\n",
    "\n",
    "| **Risk**             | **STRIDE**      | **DASF**            | **MITRE ATLAS**                  | **IBM AI Risk Atlas**                      | **NIST 800-53 Rev 5** |\n",
    "| -------------------- | --------------- | ------------------- | -------------------------------- | ------------------------------------------ | --------------------- |\n",
    "| Data Poisoning       | Tampering       | Data Poisoning      | TA0029 Data Manipulation         | Data poisoning                             | SI-10, SA-11, SI-3    |\n",
    "| PHI Leakage          | Info Disclosure | Privacy Leakage     | TA0040 Model Evasion             | Personal info exposure, Reidentification   | AC-3, SC-28, PL-8     |\n",
    "| Ontology Drift       | Tampering       | Model Misalignment  | TA0022 Supply Chain Manipulation | Unrepresentative data, Improper retraining | SA-10, CM-2, CA-7     |\n",
    "| Data Provenance Loss | Repudiation     | Data Integrity Risk | TA0022                           | Uncertain data provenance                  | AU-9, PL-8, SI-12     |\n",
    "| Biased Training Data | Tampering       | Data Bias           | TA0029                           | Fairness (Discrimination)                  | RA-8, SA-11, PM-16    |\n",
    "\n",
    "---\n",
    "\n",
    "### **B. Model Layer**\n",
    "\n",
    "| **Risk**                       | **STRIDE**           | **DASF**             | **MITRE ATLAS**            | **IBM AI Risk Atlas**               | **NIST**           |\n",
    "| ------------------------------ | -------------------- | -------------------- | -------------------------- | ----------------------------------- | ------------------ |\n",
    "| Prompt Injection               | Tampering            | Prompt Injection     | TA0010 Input Manipulation  | Prompt injection                    | SI-10, SC-23, RA-5 |\n",
    "| Hallucination                  | Tampering/Disclosure | Unsafe Generation    | TA0042 Output Manipulation | Hallucination, Unexplainable output | SA-11, SI-4, SR-11 |\n",
    "| Model Poisoning                | Tampering            | Training Poisoning   | TA0029                     | Data poisoning                      | SA-12, SI-7        |\n",
    "| Overfitting / PHI Memorization | Disclosure           | Privacy Leakage      | TA0040 Model Evasion       | Membership inference, Data leakage  | PL-8, SC-28, SI-12 |\n",
    "| Bias in Model Outputs          | Tampering            | Bias Amplification   | TA0042 Output Manipulation | Fairness, Discrimination            | RA-8, SA-11, PM-16 |\n",
    "| Model Extraction               | Disclosure           | Model Theft          | TA0040                     | Extraction attack                   | SC-28, SI-4, SR-11 |\n",
    "| Adversarial Inputs (Evasion)   | Tampering            | Adversarial Examples | TA0010                     | Evasion attack                      | SI-10, SC-23       |\n",
    "\n",
    "---\n",
    "\n",
    "### **C. Agent Layer**\n",
    "\n",
    "| **Risk**                  | **STRIDE**         | **DASF**     | **MITRE ATLAS**       | **IBM AI Risk Atlas**                         | **NIST**          |\n",
    "| ------------------------- | ------------------ | ------------ | --------------------- | --------------------------------------------- | ----------------- |\n",
    "| Agent Bypass              | Elevation          | Model Misuse | TA0040                | Unauthorized use (Agent)                      | AC-6, IA-2        |\n",
    "| Insider Threat            | Spoofing/Elevation | Misuse       | TA0017 Insider Threat | Accountability gap                            | AC-2, PS-3, AU-6  |\n",
    "| Weak Auditability         | Repudiation        | Audit Gap    | TA0040                | Lack of transparency, Untraceable attribution | AU-2, AU-12       |\n",
    "| Misaligned Agent Actions  | Tampering          | Agent Misuse | TA0042                | Value alignment gap                           | PL-2, SA-11, PM-9 |\n",
    "| Over/Under-Reliance on AI | Repudiation        | HITL Failure | TA0042                | Over/under-reliance                           | AT-2, AC-2, AU-12 |\n",
    "\n",
    "---\n",
    "\n",
    "### **D. Deployment & Integration Layer**\n",
    "\n",
    "| **Risk**             | **STRIDE**         | **DASF**             | **MITRE ATLAS**             | **IBM AI Risk Atlas**                   | **NIST**           |\n",
    "| -------------------- | ------------------ | -------------------- | --------------------------- | --------------------------------------- | ------------------ |\n",
    "| Unauthorized Access  | Spoofing/Elevation | Unauthorized Use     | TA0001 Initial Access       | Unauthorized use                        | AC-3, AC-17, SC-12 |\n",
    "| Improper Integration | Tampering          | EHR Integration Risk | TA0022 Supply Chain         | Improper curation, Uncertain provenance | SA-10, SI-10, IA-5 |\n",
    "| DoS Attack           | DoS                | Availability Attack  | TA0041 Resource Consumption | Computational inefficiency              | SC-5, SC-6         |\n",
    "| Human Error          | Repudiation        | HITL Failure         | TA0042                      | Over/under-reliance                     | AT-2, AC-2, AU-12  |\n",
    "| Insecure APIs        | Spoofing/Tampering | Integration Risk     | TA0001                      | API vulnerabilities                     | AC-3, SC-12, SI-10 |\n",
    "\n",
    "---\n",
    "\n",
    "### **E. Governance & Monitoring**\n",
    "\n",
    "| **Risk**               | **STRIDE**      | **DASF**              | **MITRE ATLAS**      | **IBM AI Risk Atlas**                             | **NIST**           |\n",
    "| ---------------------- | --------------- | --------------------- | -------------------- | ------------------------------------------------- | ------------------ |\n",
    "| Model Drift            | Tampering       | Model Misuse          | TA0040               | Incomplete evaluation, Maintenance risk           | CA-7, SA-11, PM-9  |\n",
    "| Compliance Drift       | Repudiation     | Reg. Non-Compliance   | TA0011 Policy Bypass | AI compliance gap                                 | PL-2, PL-8, CA-2   |\n",
    "| Silent Failures        | DoS/Repudiation | Monitoring Gaps       | TA0040               | Lack of transparency, Incomplete usage definition | SI-4, IR-4, AU-6   |\n",
    "| Lack of Explainability | Repudiation     | Interpretability Gaps | TA0042               | Explainability gap                                | SA-11, PL-8, PM-16 |\n",
    "| Governance Failure     | Repudiation     | Policy Risk           | TA0011               | Governance, Accountability, Transparency          | PM-9, PL-2, CA-2   |\n",
    "\n",
    "---\n",
    "\n",
    "# 🔑 Observations\n",
    "\n",
    "✅ Now all **critical AI risks** are captured across frameworks:\n",
    "\n",
    "* **Data-level**: Poisoning, PHI, bias, provenance\n",
    "* **Model-level**: Hallucination, extraction, adversarial inputs, memorization\n",
    "* **Agent-level**: Bypass, insider misuse, misaligned actions\n",
    "* **Deployment-level**: Unauthorized access, integration failures, insecure APIs, DoS, HITL risk\n",
    "* **Governance-level**: Drift, compliance, explainability, monitoring gaps\n",
    "\n",
    "✅ Each risk is mapped to:\n",
    "\n",
    "* **STRIDE** → software threat type\n",
    "* **DASF 2.0** → AI/ML risk lens\n",
    "* **MITRE ATLAS** → adversary tactics\n",
    "* **IBM AI Risk Atlas** → governance + generative/agent-specific lens\n",
    "* **NIST 800-53 Rev 5** → compliance controls\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c2e5bd-3fc6-41b5-b7fb-4f4ac1049eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI_Threat_Vector_Crosswalk.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Expanded Threat Vector Risk Catalog as structured data\n",
    "data = [\n",
    "    # DataOps Layer\n",
    "    (\"DataOps\", \"Data Poisoning\", \"Tampering\", \"Data Poisoning\", \"TA0029 Data Manipulation\", \"Data poisoning\", \"SI-10, SA-11, SI-3\"),\n",
    "    (\"DataOps\", \"PHI Leakage\", \"Info Disclosure\", \"Privacy Leakage\", \"TA0040 Model Evasion\", \"Personal info exposure, Reidentification\", \"AC-3, SC-28, PL-8\"),\n",
    "    (\"DataOps\", \"Ontology Drift\", \"Tampering\", \"Model Misalignment\", \"TA0022 Supply Chain Manipulation\", \"Unrepresentative data, Improper retraining\", \"SA-10, CM-2, CA-7\"),\n",
    "    (\"DataOps\", \"Data Provenance Loss\", \"Repudiation\", \"Data Integrity Risk\", \"TA0022\", \"Uncertain data provenance\", \"AU-9, PL-8, SI-12\"),\n",
    "    (\"DataOps\", \"Biased Training Data\", \"Tampering\", \"Data Bias\", \"TA0029\", \"Fairness (Discrimination)\", \"RA-8, SA-11, PM-16\"),\n",
    "    \n",
    "    # Model Layer\n",
    "    (\"Model\", \"Prompt Injection\", \"Tampering\", \"Prompt Injection\", \"TA0010 Input Manipulation\", \"Prompt injection\", \"SI-10, SC-23, RA-5\"),\n",
    "    (\"Model\", \"Hallucination\", \"Tampering/Disclosure\", \"Unsafe Generation\", \"TA0042 Output Manipulation\", \"Hallucination, Unexplainable output\", \"SA-11, SI-4, SR-11\"),\n",
    "    (\"Model\", \"Model Poisoning\", \"Tampering\", \"Training Poisoning\", \"TA0029\", \"Data poisoning\", \"SA-12, SI-7\"),\n",
    "    (\"Model\", \"Overfitting / PHI Memorization\", \"Disclosure\", \"Privacy Leakage\", \"TA0040 Model Evasion\", \"Membership inference, Data leakage\", \"PL-8, SC-28, SI-12\"),\n",
    "    (\"Model\", \"Bias in Model Outputs\", \"Tampering\", \"Bias Amplification\", \"TA0042 Output Manipulation\", \"Fairness, Discrimination\", \"RA-8, SA-11, PM-16\"),\n",
    "    (\"Model\", \"Model Extraction\", \"Disclosure\", \"Model Theft\", \"TA0040\", \"Extraction attack\", \"SC-28, SI-4, SR-11\"),\n",
    "    (\"Model\", \"Adversarial Inputs (Evasion)\", \"Tampering\", \"Adversarial Examples\", \"TA0010\", \"Evasion attack\", \"SI-10, SC-23\"),\n",
    "    \n",
    "    # Agent Layer\n",
    "    (\"Agent\", \"Agent Bypass\", \"Elevation\", \"Model Misuse\", \"TA0040\", \"Unauthorized use (Agent)\", \"AC-6, IA-2\"),\n",
    "    (\"Agent\", \"Insider Threat\", \"Spoofing/Elevation\", \"Misuse\", \"TA0017 Insider Threat\", \"Accountability gap\", \"AC-2, PS-3, AU-6\"),\n",
    "    (\"Agent\", \"Weak Auditability\", \"Repudiation\", \"Audit Gap\", \"TA0040\", \"Lack of transparency, Untraceable attribution\", \"AU-2, AU-12\"),\n",
    "    (\"Agent\", \"Misaligned Agent Actions\", \"Tampering\", \"Agent Misuse\", \"TA0042\", \"Value alignment gap\", \"PL-2, SA-11, PM-9\"),\n",
    "    (\"Agent\", \"Over/Under-Reliance on AI\", \"Repudiation\", \"HITL Failure\", \"TA0042\", \"Over/under-reliance\", \"AT-2, AC-2, AU-12\"),\n",
    "    \n",
    "    # Deployment Layer\n",
    "    (\"Deployment\", \"Unauthorized Access\", \"Spoofing/Elevation\", \"Unauthorized Use\", \"TA0001 Initial Access\", \"Unauthorized use\", \"AC-3, AC-17, SC-12\"),\n",
    "    (\"Deployment\", \"Improper Integration\", \"Tampering\", \"EHR Integration Risk\", \"TA0022 Supply Chain\", \"Improper curation, Uncertain provenance\", \"SA-10, SI-10, IA-5\"),\n",
    "    (\"Deployment\", \"DoS Attack\", \"DoS\", \"Availability Attack\", \"TA0041 Resource Consumption\", \"Computational inefficiency\", \"SC-5, SC-6\"),\n",
    "    (\"Deployment\", \"Human Error\", \"Repudiation\", \"HITL Failure\", \"TA0042\", \"Over/under-reliance\", \"AT-2, AC-2, AU-12\"),\n",
    "    (\"Deployment\", \"Insecure APIs\", \"Spoofing/Tampering\", \"Integration Risk\", \"TA0001\", \"API vulnerabilities\", \"AC-3, SC-12, SI-10\"),\n",
    "    \n",
    "    # Governance Layer\n",
    "    (\"Governance\", \"Model Drift\", \"Tampering\", \"Model Misuse\", \"TA0040\", \"Incomplete evaluation, Maintenance risk\", \"CA-7, SA-11, PM-9\"),\n",
    "    (\"Governance\", \"Compliance Drift\", \"Repudiation\", \"Regulatory Non-Compliance\", \"TA0011 Policy Bypass\", \"AI compliance gap\", \"PL-2, PL-8, CA-2\"),\n",
    "    (\"Governance\", \"Silent Failures\", \"DoS/Repudiation\", \"Monitoring Gaps\", \"TA0040\", \"Lack of transparency, Incomplete usage definition\", \"SI-4, IR-4, AU-6\"),\n",
    "    (\"Governance\", \"Lack of Explainability\", \"Repudiation\", \"Interpretability Gaps\", \"TA0042\", \"Explainability gap\", \"SA-11, PL-8, PM-16\"),\n",
    "    (\"Governance\", \"Governance Failure\", \"Repudiation\", \"Policy Risk\", \"TA0011\", \"Governance, Accountability, Transparency\", \"PM-9, PL-2, CA-2\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"Layer\", \"Risk\", \"STRIDE\", \"DASF 2.0\", \"MITRE ATLAS\", \"IBM AI Risk Atlas\", \"NIST 800-53 Rev 5 Controls\"\n",
    "])\n",
    "\n",
    "# Save CSV\n",
    "csv_path = \"AI_Threat_Vector_Crosswalk.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e980d930-4651-40dd-a436-6d9b1a13318b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('heatmap_by_layer.png', 'heatmap_by_framework.png')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# We'll create two heatmaps:\n",
    "# 1. Grouped by System Layer\n",
    "# 2. Grouped by Framework Lens\n",
    "\n",
    "# Assign severity values (Critical=4, High=3, Medium=2, Low=1)\n",
    "# For simplicity, we'll map risks roughly by impact (could be tuned with SME input).\n",
    "severity_map = {\n",
    "    \"Data Poisoning\": 3,\n",
    "    \"PHI Leakage\": 4,\n",
    "    \"Ontology Drift\": 2,\n",
    "    \"Data Provenance Loss\": 2,\n",
    "    \"Biased Training Data\": 3,\n",
    "    \"Prompt Injection\": 3,\n",
    "    \"Hallucination\": 4,\n",
    "    \"Model Poisoning\": 3,\n",
    "    \"Overfitting / PHI Memorization\": 4,\n",
    "    \"Bias in Model Outputs\": 3,\n",
    "    \"Model Extraction\": 3,\n",
    "    \"Adversarial Inputs (Evasion)\": 3,\n",
    "    \"Agent Bypass\": 2,\n",
    "    \"Insider Threat\": 4,\n",
    "    \"Weak Auditability\": 2,\n",
    "    \"Misaligned Agent Actions\": 3,\n",
    "    \"Over/Under-Reliance on AI\": 2,\n",
    "    \"Unauthorized Access\": 4,\n",
    "    \"Improper Integration\": 3,\n",
    "    \"DoS Attack\": 2,\n",
    "    \"Human Error\": 2,\n",
    "    \"Insecure APIs\": 3,\n",
    "    \"Model Drift\": 3,\n",
    "    \"Compliance Drift\": 4,\n",
    "    \"Silent Failures\": 3,\n",
    "    \"Lack of Explainability\": 3,\n",
    "    \"Governance Failure\": 4\n",
    "}\n",
    "\n",
    "df[\"Severity\"] = df[\"Risk\"].map(severity_map)\n",
    "\n",
    "# 1. Heatmap by System Layer (avg severity per risk under each layer)\n",
    "layer_severity = df.groupby(\"Layer\")[\"Severity\"].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.heatmap(layer_severity.pivot_table(index=\"Layer\", values=\"Severity\"), annot=True, cmap=\"YlOrRd\", cbar_kws={'label': 'Severity'})\n",
    "plt.title(\"AI Clinical Notes Scribe - Heatmap by System Layer\")\n",
    "plt.tight_layout()\n",
    "plt_path_layer = \"heatmap_by_layer.png\"\n",
    "plt.savefig(plt_path_layer)\n",
    "plt.close()\n",
    "\n",
    "# 2. Heatmap by Framework Lens (count of risks mapped to each framework)\n",
    "frameworks = [\"STRIDE\", \"DASF 2.0\", \"MITRE ATLAS\", \"IBM AI Risk Atlas\", \"NIST 800-53 Rev 5 Controls\"]\n",
    "framework_counts = {fw: [] for fw in frameworks}\n",
    "\n",
    "for fw in frameworks:\n",
    "    for layer in df[\"Layer\"].unique():\n",
    "        count = df[df[\"Layer\"] == layer][fw].nunique()\n",
    "        framework_counts[fw].append(count)\n",
    "\n",
    "framework_df = pd.DataFrame(framework_counts, index=df[\"Layer\"].unique())\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(framework_df, annot=True, cmap=\"PuBuGn\", cbar_kws={'label': 'Unique Risks Mapped'})\n",
    "plt.title(\"AI Clinical Notes Scribe - Heatmap by Framework Lens per Layer\")\n",
    "plt.tight_layout()\n",
    "plt_path_framework = \"heatmap_by_framework.png\"\n",
    "plt.savefig(plt_path_framework)\n",
    "plt.close()\n",
    "\n",
    "plt_path_layer, plt_path_framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36dc5eb-49d0-4187-b2f6-d5e6e811aa3b",
   "metadata": {},
   "source": [
    "\n",
    "# 👥 User Interaction Diagram with Risks + Controls\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant C as 👩‍⚕️ Clinician\n",
    "    participant STT as 🎙️ Speech-to-Text\n",
    "    participant LLM as 🧠 Summarization Model\n",
    "    participant SAFE as 🛡️ Safety Classifier\n",
    "    participant UI as 🖥️ Review Interface\n",
    "    participant EHR as 📂 EHR System\n",
    "\n",
    "    C->>STT: Provides audio input\n",
    "    Note over STT: Risk: Data Poisoning / PHI Leakage<br>Control: Input validation, encryption, RBAC\n",
    "\n",
    "    STT->>LLM: Sends transcript\n",
    "    Note over LLM: Risk: Prompt Injection / Hallucination<br>Control: Guardrails, ontology grounding, adversarial testing\n",
    "\n",
    "    LLM->>SAFE: Draft notes\n",
    "    Note over SAFE: Risk: Model Bias / Unsafe Generation<br>Control: Bias detection, explainability, classifier\n",
    "\n",
    "    SAFE->>UI: Validated notes\n",
    "    Note over UI: Risk: Insider Threat / Human Error<br>Control: HITL enforced, audit trails, RBAC\n",
    "\n",
    "    UI->>C: Clinician reviews & approves\n",
    "    C->>EHR: Submits approved notes\n",
    "    Note over EHR: Risk: Unauthorized Access / Improper Integration<br>Control: FHIR validation, OAuth2 + mTLS, schema checks\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 🔑 Explanation\n",
    "\n",
    "* **Speech-to-Text (STT)** → where **Data Poisoning** & **PHI Leakage** risks occur. Mitigated with **input validation + secure storage**.\n",
    "* **LLM Summarization** → biggest AI attack surface: **Prompt Injection** + **Hallucination**. Needs **guardrails + grounding + adversarial testing**.\n",
    "* **Safety Classifier** → must mitigate **Bias** + **Unsafe Output** before clinician sees it.\n",
    "* **Review Interface** → risk of **Insider Threat** (staff misusing overrides) + **Human Error** (approving unsafe notes). Needs **RBAC + audit trails**.\n",
    "* **EHR Integration** → risk of **Unauthorized Access** or **Improper Mapping**. Needs **Zero Trust API security + schema validation**.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655e6dde-3b4d-4bf0-bd44-471726f37555",
   "metadata": {},
   "source": [
    "# 👥 User Interaction Diagram with Risks + Controls + Severity\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant C as 👩‍⚕️ Clinician\n",
    "    participant STT as 🎙️ Speech-to-Text\n",
    "    participant LLM as 🧠 Summarization Model\n",
    "    participant SAFE as 🛡️ Safety Classifier\n",
    "    participant UI as 🖥️ Review Interface\n",
    "    participant EHR as 📂 EHR System\n",
    "\n",
    "    C->>STT: Provides audio input\n",
    "    Note over STT: ⚠️ Critical: PHI Leakage<br>🟥 High: Data Poisoning<br>Controls: Input validation, de-ID, RBAC, encryption\n",
    "\n",
    "    STT->>LLM: Sends transcript\n",
    "    Note over LLM: ⚠️ Critical: Hallucination<br>🟥 High: Prompt Injection<br>Controls: Guardrails, ontology grounding, adversarial testing\n",
    "\n",
    "    LLM->>SAFE: Draft notes\n",
    "    Note over SAFE: 🟥 High: Model Bias / Unsafe Generation<br>Controls: Bias detection, classifier, explainability hooks\n",
    "\n",
    "    SAFE->>UI: Validated notes\n",
    "    Note over UI: ⚠️ Critical: Insider Threat<br>🟧 Medium: Human Error<br>Controls: RBAC, MFA, audit trails, enforced HITL review\n",
    "\n",
    "    UI->>C: Clinician reviews & approves\n",
    "    C->>EHR: Submits approved notes\n",
    "    Note over EHR: ⚠️ Critical: Unauthorized Access<br>🟥 High: Improper Integration<br>Controls: OAuth2 + mTLS, FHIR schema validation, API gateway\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# 🔑 Severity Coding\n",
    "\n",
    "* **⚠️ Critical** = must-have controls (e.g., PHI leakage, hallucination, insider threat, unauthorized access).\n",
    "* **🟥 High** = strong mitigation needed, but with lower impact if contained (e.g., data poisoning, prompt injection, bias).\n",
    "* **🟧 Medium** = important, but secondary to Critical/High (e.g., human error).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eefc02e-b121-49dd-aa7c-e06e71adb322",
   "metadata": {},
   "source": [
    "We can combine the **User Interaction Risk Diagram** with the **Multi-Layer Heatmap** into a **two-pane artifact**.\n",
    "\n",
    "The idea is:\n",
    "\n",
    "* **Left pane (sequence diagram)** → shows **where in the user workflow risks occur**, tagged with severity + controls.\n",
    "* **Right pane (heatmap)** → shows **system-level risk concentration by layer** (DataOps, Model, Agent, Deployment, Governance).\n",
    "\n",
    "---\n",
    "\n",
    "# 📊 Combined Artifact (Workflow + Heatmap)\n",
    "\n",
    "```mermaid\n",
    "%% Left Pane: User Interaction with Severity\n",
    "sequenceDiagram\n",
    "    participant C as 👩‍⚕️ Clinician\n",
    "    participant STT as 🎙️ Speech-to-Text\n",
    "    participant LLM as 🧠 Summarization Model\n",
    "    participant SAFE as 🛡️ Safety Classifier\n",
    "    participant UI as 🖥️ Review Interface\n",
    "    participant EHR as 📂 EHR System\n",
    "\n",
    "    C->>STT: Provides audio input\n",
    "    Note over STT: ⚠️ Critical: PHI Leakage<br>🟥 High: Data Poisoning<br>Controls: Input validation, de-ID, RBAC, encryption\n",
    "\n",
    "    STT->>LLM: Sends transcript\n",
    "    Note over LLM: ⚠️ Critical: Hallucination<br>🟥 High: Prompt Injection<br>Controls: Guardrails, ontology grounding, adversarial testing\n",
    "\n",
    "    LLM->>SAFE: Draft notes\n",
    "    Note over SAFE: 🟥 High: Model Bias / Unsafe Generation<br>Controls: Bias detection, classifier, explainability hooks\n",
    "\n",
    "    SAFE->>UI: Validated notes\n",
    "    Note over UI: ⚠️ Critical: Insider Threat<br>🟧 Medium: Human Error<br>Controls: RBAC, MFA, audit trails, enforced HITL review\n",
    "\n",
    "    UI->>C: Clinician reviews & approves\n",
    "    C->>EHR: Submits approved notes\n",
    "    Note over EHR: ⚠️ Critical: Unauthorized Access<br>🟥 High: Improper Integration<br>Controls: OAuth2 + mTLS, FHIR schema validation, API gateway\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔥 Heatmap (Right Pane)\n",
    "\n",
    "We already have this generated as an image — here’s the link:\n",
    "📂 [Download Heatmap by Layer](heatmap_by_layer.png)\n",
    "\n",
    "---\n",
    "\n",
    "# 🔑 Present\n",
    "\n",
    "* Use **two-pane slides or dashboard view**:\n",
    "\n",
    "  * **Left (Workflow Threats)** → Shows clinicians where in their workflow risks are surfaced + what protections exist.\n",
    "  * **Right (System Heatmap)** → Shows technical teams where the risk *concentration* lies in the architecture.\n",
    "\n",
    "Together, this forms a **narrative**:\n",
    "\n",
    "1. Risks emerge naturally in the clinician → AI → EHR workflow.\n",
    "2. Heatmap confirms where wemust prioritize **controls & governance investments**.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a31b13-2b5a-4ed6-9492-2a37f59e415c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
